bmi < 18.5 ~ "Underweight",
bmi >= 18.5 & bmi < 25 ~ "Normal",
bmi >= 25 & bmi < 30 ~ "Overweight",
bmi >= 30 ~ "Obese",
TRUE ~ "Unknown"
)) %>%
# mutate(fat_percentage_category = mapply(categorize_bfp, bmi_category)) %>%
mutate(fat_percentage_category = factor(
mapply(categorize_bfp, bmi_category),
levels = c("Low", "Moderate", "High", "Extreme")
)) %>%
mutate( # This part was written with the help of ChatGPT
height_category = cut(
height,
breaks = c(-Inf, min_height, seq(min_height + 10, max_height, by = 10), Inf),  # Add breaks for below 150 and above 180
labels = c("Shorter than 150", "150-160", "160-170", "170-180", "Taller than 180"),  # Define labels
include.lowest = TRUE,  # Include the lowest value (150) in the first category
right = FALSE  # Make intervals left-closed, so 150 goes into the "150-160" range
)
)
cleaned_data$fat_percentage_category <- factor(cleaned_data_model$fat_percentage_category,
levels = c("Moderate", "Low", "High", "Extreme"))
#### Save data ####
write_parquet(cleaned_data, "data/analysis_data/measurements_analysis_data.parquet")
#### Preamble ####
# Purpose: Model for Measurements Data and Body Composition Data
# Author: Aamishi Avarsekar
# Date: 3rd Decemeber 2024
# Contact: aamishi.avarsekar@mail.utoronto.ca
# License: MIT
# Note: Aspects of this code was written with the aid of ChatGPT 4.0
# Works pace setup - packages needed
library(tidyverse)
library(arrow)
library(nnet)
library(tidyr)
library(brms)
#### Read data ####
cleaned_data_model <- read_parquet("data/analysis_data/measurements_analysis_data.parquet")
body_mass_model <- read_parquet("data/analysis_data/body_mass_data.parquet")
# Multinomial logistic regression model
measurements_model <- multinom(fat_percentage_category ~ height + gender + waist_hip_ratio + height_hip_ratio, data = cleaned_data_model)
cleaned_data_model$predicted_category <- predict(measurements_model, newdata = cleaned_data_model)
body_mass_model_bmi <- multinom(fat_percentage_category ~ age + height + gender + fm, data = body_mass_model)
body_mass_model$predicted_category <- predict(body_mass_model_bmi, newdata = body_mass_model)
summary(measurements_model)
#### Save model ####
write_parquet(cleaned_data_model, "data/analysis_data/measurements_analysis_data.parquet")
saveRDS(
measurements_model,
file = "models/measurements_model.rds"
)
write_parquet(body_mass_model, "data/analysis_data/body_mass_data.parquet")
saveRDS(
body_mass_model_bmi,
file = "models/body_mass_model_bmi.rds"
)
summary(measurements_model)
#### Preamble ####
# Purpose: Cleans the Measurements Data (BodyM)
# Author: Aamishi Avarsekar
# Date: 3rd Decemeber 2024
# Contact: aamishi.avarsekar@mail.utoronto.ca
# License: MIT
# Note: Aspects of this code was written with the aid of ChatGPT 4.0
# Work space setup
library(tidyverse)
library(janitor)
library(arrow)
library(dplyr)
# Read MEASUREMENTS DATA (AWS - BodyM)
measurements_subject_data <- read_parquet("data/raw_data/measurements_subject_data.parquet")
measurements_data <- read_parquet("data/raw_data/measurements_data.parquet")
#### Clean data ####
# Written with the help of ChatGPT with modifications
# fat categories with BMI as a proxy
categorize_bfp <- function(bmi_category) {
if (bmi_category == "Underweight") {
return("Low")
} else if (bmi_category == "Normal") {
return("Moderate")
} else if (bmi_category == "Overweight") {
return("High")
} else {
return("Extreme")
}
}
combined_data <- merge(measurements_subject_data, measurements_data, by = "subject_id")
min_height <- 150
max_height <- 180
cleaned_data <- combined_data %>%
clean_names() %>%
mutate(gender = as.numeric(factor(combined_data$gender, levels = c("male", "female")))) %>%
mutate(waist_hip_ratio = waist / hip) %>%
mutate(height_hip_ratio = height_cm / hip) %>%
mutate(original_bmi = weight_kg / (height_cm / 100)^2) %>%
mutate(subject_id = seq(1, nrow(combined_data))) %>%
select(-height) %>%
rename(
height = height_cm,
weight = weight_kg,
bmi = original_bmi
) %>%
select(subject_id, gender, height, weight, ankle, wrist, waist_hip_ratio, height_hip_ratio, bmi) %>%
mutate(
bmi_category = case_when(
bmi < 18.5 ~ "Underweight",
bmi >= 18.5 & bmi < 25 ~ "Normal",
bmi >= 25 & bmi < 30 ~ "Overweight",
bmi >= 30 ~ "Obese",
TRUE ~ "Unknown"
)) %>%
# mutate(fat_percentage_category = mapply(categorize_bfp, bmi_category)) %>%
mutate(fat_percentage_category = factor(
mapply(categorize_bfp, bmi_category),
levels = c("Moderate", "Low", "High", "Extreme")
)) %>%
mutate( # This part was written with the help of ChatGPT
height_category = cut(
height,
breaks = c(-Inf, min_height, seq(min_height + 10, max_height, by = 10), Inf),  # Add breaks for below 150 and above 180
labels = c("Shorter than 150", "150-160", "160-170", "170-180", "Taller than 180"),  # Define labels
include.lowest = TRUE,  # Include the lowest value (150) in the first category
right = FALSE  # Make intervals left-closed, so 150 goes into the "150-160" range
)
)
#### Save data ####
write_parquet(cleaned_data, "data/analysis_data/measurements_analysis_data.parquet")
#### Preamble ####
# Purpose: Tests Measurements (BodyM) data
# Author: Aamishi Avarsekar
# Date: 3rd December 2024
# Contact: aamishi.avarsekar@mail.utoronto.ca
# License: MIT
# This was written by ChatGPT
#### Workspace setup ####
library(tidyverse)
#### Test data ####
measurement_data_testing<- read_parquet("data/analysis_data/measurements_analysis_data.parquet")
library(testthat)
# Function to simulate the data
simulate_data <- function(num_rows = 1000) {
subject_id <- paste0("ID_", 1:num_rows)
gender <- sample(c("Male", "Female"), num_rows, replace = TRUE)
height <- runif(num_rows, 150, 200)  # Height in cm
weight <- runif(num_rows, 40, 100)  # Weight in kg
ankle <- runif(num_rows, 20, 30)  # Ankle circumference in cm
wrist <- runif(num_rows, 12, 20)  # Wrist circumference in cm
waist_hip_ratio <- runif(num_rows, 0.6, 1.0)  # Waist-to-hip ratio
height_hip_ratio <- height / (waist_hip_ratio * 2)  # Example height-to-hip ratio formula
# Simulate BMI
bmi <- weight / (height / 100)^2
# Create BMI categories based on common ranges
bmi_category <- cut(bmi, breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
labels = c("Underweight", "Normal", "Overweight", "Obese"))
# Simulate fat percentage categories
fat_percentage_category <- sample(c("Low", "Moderate", "High", "Extreme"), num_rows, replace = TRUE)
# Height categories (e.g., Low, Medium, High)
height_category <- cut(height, breaks = c(-Inf, 160, 180, Inf),
labels = c("Short", "Average", "Tall"))
# Combine all variables into a data frame
data.frame(
subject_id, gender, height, weight, ankle, wrist, waist_hip_ratio,
height_hip_ratio, bmi, bmi_category, fat_percentage_category, height_category
)
}
# Test 1: Check if the dataset contains the expected columns
test_that("Dataset has expected columns", {
simulated_data <- simulate_data()
expected_columns <- c("subject_id", "gender", "height", "weight", "ankle", "wrist",
"waist_hip_ratio", "height_hip_ratio", "bmi", "bmi_category",
"fat_percentage_category", "height_category")
expect_true(all(expected_columns %in% colnames(simulated_data)))
})
# Test 2: Check if all BMI values are within a reasonable range (18.5 to 40)
test_that("BMI values are within a reasonable range", {
simulated_data <- simulate_data()
expect_true(all(simulated_data$bmi >= 10 & simulated_data$bmi <= 70))
})
# Test 3: Ensure that the gender column only contains "Male" or "Female"
test_that("Gender values are correct", {
simulated_data <- simulate_data()
expect_true(all(simulated_data$gender %in% c("Male", "Female")))
})
# Test 4: Ensure the height categories are valid
test_that("Height categories are correct", {
simulated_data <- simulate_data()
expect_true(all(simulated_data$height_category %in% c("Short", "Average", "Tall")))
})
# Test 5: Check if fat_percentage_category has the expected values
test_that("Fat percentage categories are correct", {
simulated_data <- simulate_data()
expect_true(all(simulated_data$fat_percentage_category %in% c("Low", "Moderate", "High", "Extreme")))
})
# Test 6: Check that the waist_hip_ratio is within the expected range (0.6 to 1.0)
test_that("Waist-hip ratio is within range", {
simulated_data <- simulate_data()
expect_true(all(simulated_data$waist_hip_ratio >= 0.6 & simulated_data$waist_hip_ratio <= 1.0))
})
# Test 7: Verify that height_hip_ratio is calculated correctly
test_that("Height-to-hip ratio is calculated correctly", {
simulated_data <- simulate_data()
expect_true(all(simulated_data$height_hip_ratio == simulated_data$height / (simulated_data$waist_hip_ratio * 2)))
})
#### Preamble ####
# Purpose: Tests Body Composition data
# Author: Aamishi Avarsekar
# Date: 3rd December 2024
# Contact: aamishi.avarsekar@mail.utoronto.ca
# License: MIT
# This was written by ChatGPT
# Load necessary libraries for testing
library(testthat)
body_mass_for_testing<- read_parquet("data/analysis_data/body_mass_data.parquet")
# 3. Test if age column is within the expected range (18 to 80 years)
test_that("Age column is within the expected range", {
expect_true(all(body_mass_for_testing$age >= 18 & body_mass_for_testing$age <= 80))
})
# 4. Test if height column has values greater than zero
test_that("Height column has positive values", {
expect_true(all(body_mass_for_testing$height > 0))
})
# 5. Test if weight column has values greater than zero
test_that("Weight column has positive values", {
expect_true(all(body_mass_for_testing$weight > 0))
})
# 6. Test if fat_mass_kg column has non-negative values
test_that("Fat mass column has non-negative values", {
expect_true(all(body_mass_for_testing$fat_mass_kg >= 0))
})
# 8. Test if fat percentage categories are valid
test_that("Fat percentage category column contains valid categories", {
expect_true(all(body_mass_for_testing$fat_percentage_category %in% c("Low", "Moderate", "High", "Extreme")))
})
# 9. Test if bmi_category column contains valid categories
test_that("BMI category column contains valid categories", {
expect_true(all(body_mass_for_testing$bmi_category %in% c("Underweight", "Moderate", "Overweight", "Obese")))
})
# 11. Test if predicted_category column contains valid categories
test_that("Predicted category column contains valid categories", {
expect_true(all(body_mass_for_testing$predicted_category %in% c("Low", "Moderate", "High", "Extreme")))
})
# 12. Test if weight_category column contains valid categories
test_that("Weight category column contains valid categories", {
expect_true(all(body_mass_for_testing$weight_category %in% c("Underweight", "Normal", "Overweight", "Obese")))
})
# 13. Test if there are no missing values in the data frame
test_that("No missing values in the data", {
expect_true(all(!is.na(body_mass_for_testing)))
})
# 14. Test if body mass values are logically consistent (fat_mass_kg + ffm_kg should be close to weight)
test_that("Fat mass + Fat-free mass is close to weight", {
expect_true(all(abs((body_mass_for_testing$fat_mass_kg + body_mass_for_testing$ffm_kg) - body_mass_for_testing$weight) < 10))
})
# 15. Test if fat mass percentage is within a reasonable range (0 to 100)
test_that("Fat mass percentage is within a reasonable range", {
fat_percentage <- (body_mass_for_testing$fat_mass_kg / body_mass_for_testing$weight) * 100
expect_true(all(fat_percentage >= 0 & fat_percentage <= 100))
})
#### Preamble ####
# Purpose: Model for Measurements Data and Body Composition Data
# Author: Aamishi Avarsekar
# Date: 3rd Decemeber 2024
# Contact: aamishi.avarsekar@mail.utoronto.ca
# License: MIT
# Note: Aspects of this code was written with the aid of ChatGPT 4.0
# Works pace setup - packages needed
library(tidyverse)
library(arrow)
library(nnet)
library(tidyr)
library(brms)
#### Read data ####
cleaned_data_model <- read_parquet("data/analysis_data/measurements_analysis_data.parquet")
body_mass_model <- read_parquet("data/analysis_data/body_mass_data.parquet")
# Multinomial logistic regression model
measurements_model <- multinom(fat_percentage_category ~ height + gender + waist_hip_ratio + height_hip_ratio, data = cleaned_data_model)
cleaned_data_model$predicted_category <- predict(measurements_model, newdata = cleaned_data_model)
body_mass_model_bmi <- multinom(fat_percentage_category ~ age + height + gender + fm, data = body_mass_model)
body_mass_model$predicted_category <- predict(body_mass_model_bmi, newdata = body_mass_model)
summary(measurements_model)
#### Save model ####
write_parquet(cleaned_data_model, "data/analysis_data/measurements_analysis_data.parquet")
saveRDS(
measurements_model,
file = "models/measurements_model.rds"
)
write_parquet(body_mass_model, "data/analysis_data/body_mass_data.parquet")
saveRDS(
body_mass_model_bmi,
file = "models/body_mass_model_bmi.rds"
)
model_summary(measurements_model)
#### Preamble ####
# Purpose: Model for Measurements Data and Body Composition Data
# Author: Aamishi Avarsekar
# Date: 3rd Decemeber 2024
# Contact: aamishi.avarsekar@mail.utoronto.ca
# License: MIT
# Note: Aspects of this code was written with the aid of ChatGPT 4.0
# Works pace setup - packages needed
library(tidyverse)
library(arrow)
library(nnet)
library(tidyr)
library(brms)
#### Read data ####
cleaned_data_model <- read_parquet("data/analysis_data/measurements_analysis_data.parquet")
body_mass_model <- read_parquet("data/analysis_data/body_mass_data.parquet")
# Multinomial logistic regression model
measurements_model <- multinom(fat_percentage_category ~ height + gender + waist_hip_ratio + height_hip_ratio, data = cleaned_data_model)
cleaned_data_model$predicted_category <- predict(measurements_model, newdata = cleaned_data_model)
body_mass_model_bmi <- multinom(fat_percentage_category ~ age + height + gender + fm, data = body_mass_model)
body_mass_model$predicted_category <- predict(body_mass_model_bmi, newdata = body_mass_model)
summary(measurements_model)
#### Save model ####
write_parquet(cleaned_data_model, "data/analysis_data/measurements_analysis_data.parquet")
saveRDS(
measurements_model,
file = "models/measurements_model.rds"
)
write_parquet(body_mass_model, "data/analysis_data/body_mass_data.parquet")
saveRDS(
body_mass_model_bmi,
file = "models/body_mass_model_bmi.rds"
)
summary(measurements_model)
summary(body_mass_model_bmi)
#| echo: false
#| eval: true
#| warning: false
#| message: false
measurements_results <- cleaned_data_model %>%
select(gender, height, weight, height_category, fat_percentage_category, predicted_category) %>%
mutate(source = "Measurements")
body_composition_results <- body_mass_model %>%
select(gender, height, weight, height_category, fat_percentage_category, predicted_category) %>%
mutate(source = "Body Composition")
elongated_data <- bind_rows(measurements_results, body_composition_results)
ggplot(elongated_data, aes(x = predicted_category, fill = source)) +
geom_density(alpha = 0.5) +
facet_wrap(~ predicted_category) +
labs(title = "Density Plot of Predicted Categories by Source",
x = "Predicted Category",
y = "Density",
fill = "Source") +
theme_minimal()
colnames(measurements_results)
colnames(body_composition_results)
str(measurements_results)
str(body_composition_results)
measurements_results$predicted_category <- factor(measurements_results$predicted_category)
elongated_data <- bind_rows(measurements_results, body_composition_results)
predicted_category
View(elongated_data)
View(elongated_data)
elongated_data <- bind_rows(measurements_results, body_composition_results)
View(elongated_data)
ggplot(elongated_data, aes(x = predicted_category, fill = source)) +
geom_density(alpha = 0.5) +
# facet_wrap(~ predicted_category) +
labs(title = "Density Plot of Predicted Categories by Source",
x = "Predicted Category",
y = "Density",
fill = "Source") +
theme_minimal()
str(measurements_results)
str(body_composition_results)
measurements_results$fat_percentage_category <- factor(measurements_results$predicted_category)
str(measurements_results)
str(body_composition_results)
---
title: "Classification of Body Fat based on Measurements and Body Composition"
str(measurements_results)
str(body_composition_results)
ggplot(elongated_data, aes(x = fat_percentage_category, fill = source)) +
geom_density(alpha = 0.5) +
facet_wrap(~ fat_percentage_category) +
labs(title = "Density Plot of Predicted Categories by Source",
x = "Predicted Category",
y = "Density",
fill = "Source") +
theme_minimal()
is.data.frame(measurements_results)
is.data.frame(body_composition_results)
is.null(measurements_results)
is.null(body_composition_results)
# Check if either is empty
nrow(measurements_results) == 0
nrow(body_composition_results) == 0
sapply(measurements_results, is.list)
sapply(body_composition_results, is.list)
str(measurements_results)
str(body_composition_results)
elongated_data <- dplyr::bind_rows(measurements_results, body_composition_results)
print(category_percentage_by_source)
ggplot(category_percentage_by_source, aes(x = predicted_category, y = percentage, fill = source)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Percentage of Predicted Categories by Source",
x = "Predicted Category",
y = "Percentage (%)") +
theme_minimal() +
scale_fill_manual(values = c("Measurements" = "skyblue", "BodyComposition" = "grey")) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels if needed
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage) %>%
rename(predicted_fat = "predicted_category")  # Rename to predicted_fat if required
category_percentage_by_source
View(category_percentage_by_source)
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage) %>%
rename(predicted_fat = "predicted_category")  # Rename to predicted_fat if required
#| echo: false
#| eval: false
#| warning: false
#| message: false
levels_results <- union(levels(cleaned_data_model$predicted_category), levels(body_mass_model$predicted_category))
measurements_results <- cleaned_data_model %>%
select(height, weight, height_category, fat_percentage_category, predicted_category) %>%
mutate(source = "Measurements")
body_composition_results <- body_mass_model %>%
select(height, weight, height_category, fat_percentage_category, predicted_category) %>%
mutate(source = "BodyComposition")
elongated_data <- bind_rows(measurements_results, body_composition_results)
# Calculate the percentage of each predicted category
category_percentage_by_source <- elongated_data %>%
group_by(source, predicted_category) %>%
summarise(count = n()) %>%
mutate(percentage = (count / sum(count)) * 100) %>%
select(source, predicted_category, percentage)
category_percentage_by_source_height <- elongated_data %>%
group_by(source, height_category, predicted_category) %>%
summarise(count = n()) %>%
mutate(percentage = (count / sum(count)) * 100) %>%
select(source, height_category, predicted_category, percentage)
# Print the result
print(category_percentage_by_source)
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage) %>%
rename(predicted_fat = "predicted_category")  # Rename to predicted_fat if required
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage) %>%
rename(predicted_fat = "predicted_category")  # Rename to predicted_fat if required
category_percentage_by_source
View(category_percentage_by_source)
elongated_data <- bind_rows(measurements_results, body_composition_results)
View(elongated_data)
View(elongated_data)
category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage)
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage) %>%
rename(predicted_category = "predicted_category")  # Rename to predicted_fat if required
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage)
View(reshaped_data)
reshaped_data
reshaped_data
View(reshaped_data)
View(category_percentage_by_source)
View(category_percentage_by_source)
head(category_percentage_by_source)
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = predicted_category, values_from = percentage)
View(reshaped_data)
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = source, values_from = percentage)
View(reshaped_data)
#| echo: false
#| eval: false
#| warning: false
#| message: false
levels_results <- union(levels(cleaned_data_model$predicted_category), levels(body_mass_model$predicted_category))
measurements_results <- cleaned_data_model %>%
select(height, weight, height_category, fat_percentage_category, predicted_category) %>%
mutate(source = "Measurements")
body_composition_results <- body_mass_model %>%
select(height, weight, height_category, fat_percentage_category, predicted_category) %>%
mutate(source = "BodyComposition")
elongated_data <- bind_rows(measurements_results, body_composition_results)
# Calculate the percentage of each predicted category
category_percentage_by_source <- elongated_data %>%
group_by(source, predicted_category) %>%
summarise(count = n()) %>%
mutate(percentage = (count / sum(count)) * 100) %>%
select(source, predicted_category, percentage)
category_percentage_by_source_height <- elongated_data %>%
group_by(source, height_category, predicted_category) %>%
summarise(count = n()) %>%
mutate(percentage = (count / sum(count)) * 100) %>%
select(source, height_category, predicted_category, percentage)
# Print the result
print(category_percentage_by_source)
reshaped_data <- category_percentage_by_source %>%
pivot_wider(names_from = source, values_from = percentage)
kable(reshaped_data, format = "html", caption = "Percentage of Predicted Categories by Source")
# For the height-based reshaping (if needed), apply pivot_wider similarly:
# reshaped_data_height <- category_percentage_by_source_height %>%
#   pivot_wider(names_from = predicted_category, values_from = percentage) %>%
#   rename(predicted_fat = "predicted_category")
#
# # View reshaped data
# reshaped_data
# reshaped_data_height
# ggplot(category_percentage_by_source, aes(x = predicted_category, y = percentage, fill = source)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   labs(title = "Percentage of Predicted Categories by Source",
#        x = "Predicted Category",
#        y = "Percentage (%)") +
#   theme_minimal() +
#   scale_fill_manual(values = c("Measurements" = "skyblue", "BodyComposition" = "grey")) +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels if needed
